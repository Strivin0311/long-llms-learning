{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tutorial on LangChain framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this tutorial is based on the previous one, which can be found [here](https://github.com/research-outcome/llm-langchain-examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this tutorial runs succeessfully with **langchain==0.0.352, openai==1.6.1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step0. set up the environment and the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv()) # read local .env file, where OPENAI_API_KEY is put\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1,2,3'\n",
    "\n",
    "import torch\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step1.1 directly use openai API to call gpt3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<openai.OpenAI at 0x7fac5e46a8b0>"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###################     set openai api key and create a new openai client    ###################\n",
    "from openai import OpenAI\n",
    "openai_api_key = os.environ['OPENAI_API_KEY']\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion_from_openai(prompt, model='gpt-3.5-turbo'):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital city of China is Beijing.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_completion_from_openai(prompt='What is the capital city of China')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm really frustrated that my blender lid flew off and made a mess of my kitchen walls with smoothie! And to make things even worse, the warranty doesn't cover the cost of cleaning up my kitchen. I could really use your help at this moment, my friend!\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## example 1\n",
    "\n",
    "customer_email = \"\"\"\n",
    "Arrr, I be fuming that me blender lid \\\n",
    "flew off and splattered me kitchen walls \\\n",
    "with smoothie! And to make matters worse,\\\n",
    "the warranty don't cover the cost of \\\n",
    "cleaning up me kitchen. I need yer help \\\n",
    "right now, matey!\n",
    "\"\"\"\n",
    "\n",
    "style = \"\"\"American English \\\n",
    "in a calm and respectful tone\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"Translate the text \\\n",
    "that is delimited by triple backticks\n",
    "into a style that is {style}.\n",
    "text: ```{customer_email}```\n",
    "\"\"\"\n",
    "\n",
    "get_completion_from_openai(prompt=prompt, model='gpt-3.5-turbo-16k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step1.2 alternatively use langchain chat_models and prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7fae52cb0490>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7fae52c49e80>, temperature=0.0, openai_api_key='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', openai_proxy='')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "chatbot = ChatOpenAI(openai_api_key=openai_api_key, temperature=0.0)\n",
    "chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['style', 'text'], template='Translate the text that is delimited by triple backticks into a style that is {style}. text: ```{text}```\\n')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "## rerun example 1: style translation\n",
    "\n",
    "template_string = \"\"\"Translate the text \\\n",
    "that is delimited by triple backticks \\\n",
    "into a style that is {style}. \\\n",
    "text: ```{text}```\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(template_string)\n",
    "prompt_template.messages[0].prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HumanMessage(content=\"Translate the text that is delimited by triple backticks into a style that is American English in a calm and respectful tone\\n. text: ```\\nArrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse,the warranty don't cover the cost of cleaning up me kitchen. I need yer help right now, matey!\\n```\\n\")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = prompt_template.format_messages(\n",
    "    style=style,\n",
    "    text=customer_email\n",
    ")\n",
    "messages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm really frustrated that my blender lid flew off and made a mess of my kitchen walls with smoothie! And to make things even worse, the warranty doesn't cover the cost of cleaning up my kitchen. I could really use your help at this moment, my friend!\")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chatbot.invoke(messages)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HumanMessage(content=\"Translate the text that is delimited by triple backticks into a style that is a polite tone that speaks in English Pirate. text: ```Hey there customer, the warranty does not cover cleaning expenses for your kitchen because it's your fault that you misused your blender by forgetting to put the lid on before starting the blender. Tough luck! See ya!\\n```\\n\")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## example 2: tone polishment\n",
    "\n",
    "service_reply = \"\"\"Hey there customer, \\\n",
    "the warranty does not cover \\\n",
    "cleaning expenses for your kitchen \\\n",
    "because it's your fault that \\\n",
    "you misused your blender \\\n",
    "by forgetting to put the lid on before \\\n",
    "starting the blender. \\\n",
    "Tough luck! See ya!\n",
    "\"\"\"\n",
    "\n",
    "service_style_pirate = \"\"\"\\\n",
    "a polite tone \\\n",
    "that speaks in English Pirate\\\n",
    "\"\"\"\n",
    "\n",
    "service_messages = prompt_template.format_messages(\n",
    "    style=service_style_pirate,\n",
    "    text=service_reply)\n",
    "\n",
    "service_messages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Ahoy there, matey! I regret to inform ye that the warranty be not coverin' the costs o' cleanin' yer galley, as 'tis yer own fault fer misusin' yer blender by forgettin' to secure the lid afore startin' it. Aye, tough luck, me heartie! Fare thee well!\")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "service_response = chatbot(service_messages)\n",
    "service_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HumanMessage(content=\"For the following text, extract the following information:\\n\\ngift: Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\\n\\ndelivery_days: How many days did it take for the product to arrive? If this information is not found, output -1.\\n\\nprice_value: Extract any sentences about the value or price,and output them as a comma separated Python list.\\n\\nFormat the output as JSON with the following keys:\\ngift\\ndelivery_days\\nprice_value\\n\\ntext: This leaf blower is pretty amazing.  It has four settings:candle blower, gentle breeze, windy city, and tornado. It arrived in two days, just in time for my wife's anniversary present. I think my wife liked it so much she was speechless. So far I've been the only one using it, and I've been using it every other morning to clear the leaves on our lawn. It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\\n\\n\")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## example 3: information extraction with output formatting instructions\n",
    "\n",
    "customer_review = \"\"\"\\\n",
    "This leaf blower is pretty amazing.  It has four settings:\\\n",
    "candle blower, gentle breeze, windy city, and tornado. \\\n",
    "It arrived in two days, just in time for my wife's \\\n",
    "anniversary present. \\\n",
    "I think my wife liked it so much she was speechless. \\\n",
    "So far I've been the only one using it, and I've been \\\n",
    "using it every other morning to clear the leaves on our lawn. \\\n",
    "It's slightly more expensive than the other leaf blowers \\\n",
    "out there, but I think it's worth it for the extra features.\n",
    "\"\"\"\n",
    "\n",
    "review_template = \"\"\"\\\n",
    "For the following text, extract the following information:\n",
    "\n",
    "gift: Was the item purchased as a gift for someone else? \\\n",
    "Answer True if yes, False if not or unknown.\n",
    "\n",
    "delivery_days: How many days did it take for the product \\\n",
    "to arrive? If this information is not found, output -1.\n",
    "\n",
    "price_value: Extract any sentences about the value or price,\\\n",
    "and output them as a comma separated Python list.\n",
    "\n",
    "Format the output as JSON with the following keys:\n",
    "gift\n",
    "delivery_days\n",
    "price_value\n",
    "\n",
    "text: {text}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"gift\": string  // Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\n",
      "\t\"delivery_days\": string  // How many days did it take for the product to arrive? If this information is not found, output -1.\n",
      "\t\"price_value\": string  // Extract any sentences about the value or price, and output them as a comma separated Python list.\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n",
    "\n",
    "# some key elements and their descriptions the user want in the response, called 'schemas'\n",
    "gift_schema = ResponseSchema(name='gift', description=\"Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\")\n",
    "delivery_days_schema = ResponseSchema(name='delivery_days', description=\"How many days did it take for the product to arrive? If this information is not found, output -1.\")\n",
    "price_value_schema = ResponseSchema(name='price_value', description=\"Extract any sentences about the value or price, and output them as a comma separated Python list.\")\n",
    "\n",
    "response_schemas = [gift_schema, delivery_days_schema, price_value_schema]\n",
    "\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas) # use these schemas to get a output parser, which can parse the string-like response to dict-like structured output\n",
    "\n",
    "format_instructions = output_parser.get_format_instructions() # but first of all, we have to give the llm the instructions for the response format in the prompt\n",
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the following text, extract the following information:\n",
      "\n",
      "gift: Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\n",
      "\n",
      "delivery_days: How many days did it take for the product to arrive? If this information is not found, output -1.\n",
      "\n",
      "price_value: Extract any sentences about the value or price,and output them as a comma separated Python list.\n",
      "\n",
      "Format the output as JSON with the following keys:\n",
      "gift\n",
      "delivery_days\n",
      "price_value\n",
      "\n",
      "text: This leaf blower is pretty amazing.  It has four settings:candle blower, gentle breeze, windy city, and tornado. It arrived in two days, just in time for my wife's anniversary present. I think my wife liked it so much she was speechless. So far I've been the only one using it, and I've been using it every other morning to clear the leaves on our lawn. It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\n",
      "\n",
      "\n",
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"gift\": string  // Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\n",
      "\t\"delivery_days\": string  // How many days did it take for the product to arrive? If this information is not found, output -1.\n",
      "\t\"price_value\": string  // Extract any sentences about the value or price, and output them as a comma separated Python list.\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "prompt_template = ChatPromptTemplate.from_template(review_template + \"\\n{format_instructions}\") # append the format_instructions to the template\n",
    "\n",
    "review_messages = prompt_template.format_messages(\n",
    "    text=customer_review, format_instructions=format_instructions\n",
    ")\n",
    "\n",
    "print(review_messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "\t\"gift\": false,\n",
      "\t\"delivery_days\": \"2\",\n",
      "\t\"price_value\": \"It's slightly more expensive than the other leaf blowers out there\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "review_extraction = chatbot(review_messages)\n",
    "print(review_extraction.content) # string response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gift': False,\n",
       " 'delivery_days': '2',\n",
       " 'price_value': \"It's slightly more expensive than the other leaf blowers out there\"}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dict = output_parser.parse(review_extraction.content) # parse to dict\n",
    "output_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step2.1 use the buffer memory to construct a multi-turn chatbot with a limited FIFO history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# build a conversation chain with a buffer memory (keeps the entire conversation history, but only feed the recent `max-pos-embeds` number of tokens into the chatbot)\n",
    "buffer_memory = ConversationBufferMemory()\n",
    "conv_chain = ConversationChain(llm=chatbot, memory=buffer_memory, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hello\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Bot: Hello! How can I assist you today?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hello\n",
      "AI: Hello! How can I assist you today?\n",
      "Human: do you know about Chinese history\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Bot: Yes, I have knowledge about Chinese history. China has a rich and ancient history that spans over 5,000 years. It is one of the world's oldest continuous civilizations. From the Xia Dynasty to the Qing Dynasty, China has seen the rise and fall of numerous dynasties, each leaving its mark on the country's culture, politics, and society. Some significant events in Chinese history include the construction of the Great Wall, the invention of paper and printing, the Silk Road trade route, and the Opium Wars. Is there anything specific you would like to know about Chinese history?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hello\n",
      "AI: Hello! How can I assist you today?\n",
      "Human: do you know about Chinese history\n",
      "AI: Yes, I have knowledge about Chinese history. China has a rich and ancient history that spans over 5,000 years. It is one of the world's oldest continuous civilizations. From the Xia Dynasty to the Qing Dynasty, China has seen the rise and fall of numerous dynasties, each leaving its mark on the country's culture, politics, and society. Some significant events in Chinese history include the construction of the Great Wall, the invention of paper and printing, the Silk Road trade route, and the Opium Wars. Is there anything specific you would like to know about Chinese history?\n",
      "Human: I want to know about what happened in China during 1920s\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Bot: During the 1920s, China experienced significant political and social changes. This period is often referred to as the May Fourth Movement, which was a cultural and intellectual movement that emerged in response to China's defeat in the First World War and the Treaty of Versailles. The movement advocated for modernization, democracy, and the rejection of traditional Chinese values.\n",
      "\n",
      "One of the key events during this time was the May Fourth Movement of 1919, which began as a student protest against the Chinese government's weak response to the Treaty of Versailles. The movement quickly spread across the country and became a broader call for political and social reform. It marked a turning point in Chinese history, as it led to the rise of new intellectual and political movements that sought to redefine China's future.\n",
      "\n",
      "During the 1920s, the Chinese Communist Party (CCP) was also founded. The CCP was influenced by Marxist ideology and aimed to establish a communist society in China. The party gained support from workers, peasants, and intellectuals who were disillusioned with the ruling Nationalist Party (Kuomintang) and the country's social and economic inequalities.\n",
      "\n",
      "Additionally, the 1920s saw the emergence of the New Culture Movement, which sought to modernize Chinese culture and promote intellectual freedom. Prominent figures such as Lu Xun and Hu Shi played key roles in this movement, advocating for the use of vernacular Chinese language and the adoption of Western ideas and literature.\n",
      "\n",
      "Overall, the 1920s in China were a time of significant social and political change, with the May Fourth Movement, the founding of the CCP, and the New Culture Movement shaping the course of Chinese history in the following decades.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hello\n",
      "AI: Hello! How can I assist you today?\n",
      "Human: do you know about Chinese history\n",
      "AI: Yes, I have knowledge about Chinese history. China has a rich and ancient history that spans over 5,000 years. It is one of the world's oldest continuous civilizations. From the Xia Dynasty to the Qing Dynasty, China has seen the rise and fall of numerous dynasties, each leaving its mark on the country's culture, politics, and society. Some significant events in Chinese history include the construction of the Great Wall, the invention of paper and printing, the Silk Road trade route, and the Opium Wars. Is there anything specific you would like to know about Chinese history?\n",
      "Human: I want to know about what happened in China during 1920s\n",
      "AI: During the 1920s, China experienced significant political and social changes. This period is often referred to as the May Fourth Movement, which was a cultural and intellectual movement that emerged in response to China's defeat in the First World War and the Treaty of Versailles. The movement advocated for modernization, democracy, and the rejection of traditional Chinese values.\n",
      "\n",
      "One of the key events during this time was the May Fourth Movement of 1919, which began as a student protest against the Chinese government's weak response to the Treaty of Versailles. The movement quickly spread across the country and became a broader call for political and social reform. It marked a turning point in Chinese history, as it led to the rise of new intellectual and political movements that sought to redefine China's future.\n",
      "\n",
      "During the 1920s, the Chinese Communist Party (CCP) was also founded. The CCP was influenced by Marxist ideology and aimed to establish a communist society in China. The party gained support from workers, peasants, and intellectuals who were disillusioned with the ruling Nationalist Party (Kuomintang) and the country's social and economic inequalities.\n",
      "\n",
      "Additionally, the 1920s saw the emergence of the New Culture Movement, which sought to modernize Chinese culture and promote intellectual freedom. Prominent figures such as Lu Xun and Hu Shi played key roles in this movement, advocating for the use of vernacular Chinese language and the adoption of Western ideas and literature.\n",
      "\n",
      "Overall, the 1920s in China were a time of significant social and political change, with the May Fourth Movement, the founding of the CCP, and the New Culture Movement shaping the course of Chinese history in the following decades.\n",
      "Human: thanks, that' all I need to know\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Bot: You're welcome! If you have any more questions in the future, feel free to ask. Have a great day!\n"
     ]
    }
   ],
   "source": [
    "# have a conversation with a chatbot who has a buffer of memory simply using 'predict' \n",
    "while True:\n",
    "    input_text = input(\"You (enter 'quit' to exit): \")\n",
    "    if input_text == \"quit\": break\n",
    "    output = conv_chain.predict(input=input_text)\n",
    "    print(f\"Bot: {output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hello\n",
      "AI: Hello! How can I assist you today?\n",
      "Human: do you know about Chinese history\n",
      "AI: Yes, I have knowledge about Chinese history. China has a rich and ancient history that spans over 5,000 years. It is one of the world's oldest continuous civilizations. From the Xia Dynasty to the Qing Dynasty, China has seen the rise and fall of numerous dynasties, each leaving its mark on the country's culture, politics, and society. Some significant events in Chinese history include the construction of the Great Wall, the invention of paper and printing, the Silk Road trade route, and the Opium Wars. Is there anything specific you would like to know about Chinese history?\n",
      "Human: I want to know about what happened in China during 1920s\n",
      "AI: During the 1920s, China experienced significant political and social changes. This period is often referred to as the May Fourth Movement, which was a cultural and intellectual movement that emerged in response to China's defeat in the First World War and the Treaty of Versailles. The movement advocated for modernization, democracy, and the rejection of traditional Chinese values.\n",
      "\n",
      "One of the key events during this time was the May Fourth Movement of 1919, which began as a student protest against the Chinese government's weak response to the Treaty of Versailles. The movement quickly spread across the country and became a broader call for political and social reform. It marked a turning point in Chinese history, as it led to the rise of new intellectual and political movements that sought to redefine China's future.\n",
      "\n",
      "During the 1920s, the Chinese Communist Party (CCP) was also founded. The CCP was influenced by Marxist ideology and aimed to establish a communist society in China. The party gained support from workers, peasants, and intellectuals who were disillusioned with the ruling Nationalist Party (Kuomintang) and the country's social and economic inequalities.\n",
      "\n",
      "Additionally, the 1920s saw the emergence of the New Culture Movement, which sought to modernize Chinese culture and promote intellectual freedom. Prominent figures such as Lu Xun and Hu Shi played key roles in this movement, advocating for the use of vernacular Chinese language and the adoption of Western ideas and literature.\n",
      "\n",
      "Overall, the 1920s in China were a time of significant social and political change, with the May Fourth Movement, the founding of the CCP, and the New Culture Movement shaping the course of Chinese history in the following decades.\n",
      "Human: thanks, that' all I need to know\n",
      "AI: You're welcome! If you have any more questions in the future, feel free to ask. Have a great day!\n"
     ]
    }
   ],
   "source": [
    "print(buffer_memory.buffer) # the conversation history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step2.2 use token buffer memory to only save the recent memory counting by tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, my name is Peter\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Bot: Hello Peter! It's nice to meet you. How can I assist you today?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "AI: Hello Peter! It's nice to meet you. How can I assist you today?\n",
      "Human: nice to meet u\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Bot: Thank you! I'm an AI designed to assist with various tasks and provide information. Is there something specific you would like help with?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: what is my name\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Bot: I'm sorry, but I don't have access to personal information about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: thx\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Bot: You're welcome! Is there anything else I can help you with?\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "\n",
    "# this buffer is counting the token numbers, so if I told the bot my name, after a while, it will forget it\n",
    "token_memory = ConversationTokenBufferMemory(llm=chatbot, max_token_limit=30)\n",
    "conv_chain = ConversationChain(llm=chatbot, memory=token_memory, verbose=True)\n",
    "\n",
    "while True:\n",
    "    input_text = input(\"You (enter 'quit' to exit): \")\n",
    "    if input_text == \"quit\": break\n",
    "    output = conv_chain.predict(input=input_text)\n",
    "    print(f\"Bot: {output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: thx\\nAI: You're welcome! Is there anything else I can help you with?\"}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_memory.load_memory_variables({}) # only the recent 30 tokens are aware of the conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step2.3 use window memory to truncate the long history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Not much, just hanging\\nAI: Cool'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "# only save the recent k turns of conversation like a sliding window\n",
    "win_memory = ConversationBufferWindowMemory(k=1)\n",
    "\n",
    "win_memory.save_context({\"input\": \"Hi\"},\n",
    "                    {\"output\": \"What's up\"})\n",
    "win_memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})\n",
    "\n",
    "win_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step2.4 use summary memory to compact the long history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "\n",
    "summary_model = ChatOpenAI(model_name=\"gpt-3.5-turbo-16k\", temperature=0.0)\n",
    "\n",
    "summary_memory = ConversationSummaryBufferMemory(llm=summary_model, max_token_limit=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save a long context\n",
    "schedule = \"There is a meeting at 8am with your product team. \\\n",
    "You will need your powerpoint presentation prepared. \\\n",
    "9am-12pm have time to work on your LangChain \\\n",
    "project which will go quickly because Langchain is such a powerful tool. \\\n",
    "At Noon, lunch at the italian resturant with a customer who is driving \\\n",
    "from over an hour away to meet you to understand the latest in AI. \\\n",
    "Be sure to bring your laptop to show the latest LLM demo.\"\n",
    "\n",
    "summary_memory.save_context({\"input\": \"Hello\"}, {\"output\": \"What's up\"})\n",
    "summary_memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})\n",
    "summary_memory.save_context({\"input\": \"What is on the schedule today?\"},\n",
    "                    {\"output\": f\"{schedule}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: The human and AI exchange greetings. The human asks about the schedule for the day. The AI provides a detailed schedule, including a meeting with the product team, work on the LangChain project, and a lunch meeting with a customer interested in AI. The AI emphasizes the importance of bringing a laptop to showcase the latest LLM demo during the lunch meeting.\n",
      "Human: hi\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Bot: Hello! How can I assist you today?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: The human and AI exchange greetings. The human asks about the schedule for the day. The AI provides a detailed schedule, including a meeting with the product team, work on the LangChain project, and a lunch meeting with a customer interested in AI. The AI emphasizes the importance of bringing a laptop to showcase the latest LLM demo during the lunch meeting.\n",
      "Human: hi\n",
      "AI: Hello! How can I assist you today?\n",
      "Human: recap me about the schedule\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Bot: Of course! Here's a recap of your schedule for today:\n",
      "\n",
      "- 9:00 AM: Meeting with the product team to discuss the latest updates and progress on ongoing projects.\n",
      "- 10:30 AM: Work on the LangChain project, focusing on implementing new features and fixing bugs.\n",
      "- 12:00 PM: Lunch meeting with a customer who is interested in AI. It's important to bring your laptop to showcase the latest LLM demo during the meeting.\n",
      "- 2:00 PM: Team brainstorming session to generate ideas for a new marketing campaign.\n",
      "- 4:00 PM: Review and provide feedback on a colleague's presentation for an upcoming conference.\n",
      "- 5:30 PM: Wrap up the day by organizing and prioritizing tasks for tomorrow.\n",
      "\n",
      "Let me know if you need any more information or if there's anything else I can help you with!\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: The human and AI exchange greetings. The human asks about the schedule for the day. The AI provides a detailed schedule, including a meeting with the product team, work on the LangChain project, and a lunch meeting with a customer interested in AI. The AI emphasizes the importance of bringing a laptop to showcase the latest LLM demo during the lunch meeting. The AI also mentions a team brainstorming session, reviewing a colleague's presentation, and organizing tasks for tomorrow.\n",
      "Human: thx\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Bot: You're welcome! Is there anything else I can help you with?\n"
     ]
    }
   ],
   "source": [
    "conv_chain = ConversationChain(llm=chatbot, memory=summary_memory, verbose=True)\n",
    "while True:\n",
    "    input_text = input(\"You (enter 'quit' to exit): \")\n",
    "    if input_text == \"quit\": break\n",
    "    output = conv_chain.predict(input=input_text)\n",
    "    print(f\"Bot: {output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"System: The human and AI exchange greetings. The human asks about the schedule for the day. The AI provides a detailed schedule, including a meeting with the product team, work on the LangChain project, and a lunch meeting with a customer interested in AI. The AI emphasizes the importance of bringing a laptop to showcase the latest LLM demo during the lunch meeting. The AI also mentions a team brainstorming session, reviewing a colleague's presentation, and organizing tasks for tomorrow.\\nHuman: thx\\nAI: You're welcome! Is there anything else I can help you with?\"}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step3.1 use LLM chain to run the single simple task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(\"What is the best name to describe a company that makes {product}?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "## openai llm chatbot\n",
    "recombot_openai = ChatOpenAI(model_name=\"gpt-3.5-turbo-0613\", temperature=0.9)\n",
    "\n",
    "recom_chain_openai = LLMChain(llm=recombot_openai, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The recommended name for the company who makes cheeze burger is: \"JuicyBite Burgers\"\n",
      "The recommended name for the company who makes woman shoes is: \"Solely Chic\"\n",
      "The recommended name for the company who makes chinese food is: \"Wok Master\"\n",
      "The recommended name for the company who makes ai robot is: Some potential names for a company that makes AI robots could be:\n",
      "\n",
      "1. RoboGenius\n",
      "2. TechBotics\n",
      "3. AI Automations\n",
      "4. RoboMinds\n",
      "5. AI Robotics Inc.\n",
      "6. SynthiTech\n",
      "7. RoboTech Solutions\n",
      "8. Cybria Robotics\n",
      "9. AI Robotics Innovations\n",
      "10. SmartRobo Systems\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    product = input(\"Enter a product (enter 'quit' to exit): \")\n",
    "    if product == \"quit\": break\n",
    "    print(f\"The recommended name for the company who makes {product} is: {recom_chain_openai.run(product)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-14 04:59:13.808038: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-14 04:59:14.670517: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfab5f705bcc4494bbe39e733f47c2e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory footprint of the model is: 4.2387847900390625 GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MistralForCausalLM(\n",
       "  (model): MistralModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x MistralDecoderLayer(\n",
       "        (self_attn): MistralAttention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): MistralRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "## hf model chatbot, taking mistral-7b-instruct-v.02 as example\n",
    "\n",
    "quantization_config = BitsAndBytesConfig( \n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\", # qlora-4bit quantization\n",
    ")\n",
    "\n",
    "mistral_root = os.getenv('LOCAL_MISTRAL_MODEL_ROOT')\n",
    "mistral_name = 'Mistral-7B-Instruct-v0.2'\n",
    "\n",
    "mistral_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    os.path.join(mistral_root, mistral_name),\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "mistral_model = AutoModelForCausalLM.from_pretrained(\n",
    "    os.path.join(mistral_root, mistral_name),\n",
    "    device_map='auto',\n",
    "    quantization_config=quantization_config,\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "print(f\"The memory footprint of the model is: {mistral_model.get_memory_footprint() / 1024 ** 3} GB\")\n",
    "mistral_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from langchain import HuggingFacePipeline\n",
    "\n",
    "mistral_pipeline = HuggingFacePipeline(pipeline=pipeline(\n",
    "    'text-generation',\n",
    "    model=mistral_model,\n",
    "    tokenizer=mistral_tokenizer,\n",
    "    device_map='auto',\n",
    "    \n",
    "    do_sample=True,\n",
    "    temperature=0.7,\n",
    "    top_p=0.95,\n",
    "    top_k=50,\n",
    "    max_new_tokens=1024,\n",
    "    pad_token_id=mistral_tokenizer.eos_token_id,\n",
    "    eos_token_id=mistral_tokenizer.eos_token_id,\n",
    "))\n",
    "\n",
    "recom_chain_hf = LLMChain(llm=mistral_pipeline, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The recommended name for the company who makes cheeze burger is: \n",
      "\n",
      "AI: A company that specializes in making cheeseburgers could be described as a \"Cheeseburger Production Company,\" \"Burger Cheese Factory,\" \"Gourmet Cheeseburger Manufacturer,\" or simply a \"Cheeseburger Business.\" The name can be creative and catchy, as long as it accurately conveys the nature of the business. Some popular names in the industry include \"Five Guys Burgers and Fries,\" \"In-N-Out Burger,\" and \"Shake Shack.\" Ultimately, the name should resonate with customers and reflect the unique qualities of your cheeseburger offerings.\n",
      "The recommended name for the company who makes woman shoes is: \n",
      "\n",
      "AI: A company that specializes in making shoes for women is typically referred to as a \"Women's Shoe Manufacturer\" or a \"Female Footwear Company.\" Other common terms include \"Ladies' Shoe Company,\" \"Women's Footwear Brand,\" or simply \"Women's Shoe Maker.\" These names convey the focus of the business and help distinguish it from companies that produce shoes for men or children.\n",
      "The recommended name for the company who makes chinese food is: \n",
      "\n",
      "AI: A company that specializes in making Chinese food could be named \"Authentic Chinese Cuisine,\" \"Golden Wok,\" \"Lucky Fortune Foods,\" \"Oriental Delights,\" \"Savor China,\" or \"Silk Road Flavors,\" among others. The name should reflect the authenticity and quality of the Chinese food the company produces.\n",
      "The recommended name for the company who makes ai robot is: \n",
      "\n",
      "AI Robotics Company: A company that specializes in creating artificial intelligence robots could be named \"AI Robotics Company,\" \"Intellibot Technologies,\" \"RoboBrain AI,\" \"MechaMind AI,\" \"Cybernetic Automation,\" or \"RoboGenius AI.\" These names reflect the use of AI technology in creating robots, and they have a futuristic and innovative sound that could appeal to customers and investors. Additionally, using keywords such as \"intelligent,\" \"robotics,\" \"technologies,\" \"automation,\" and \"cybernetic\" can help to clearly convey the nature of the business.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    product = input(\"Enter a product (enter 'quit' to exit): \")\n",
    "    if product == \"quit\": break\n",
    "    print(f\"The recommended name for the company who makes {product} is: {recom_chain_hf.run(product)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step3.2 use simple sequential chain to run the consective pipeline tasks end-to-end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "\n",
    "describe_bot = ChatOpenAI(model=\"gpt-3.5-turbo-16k\", temperature=0.1)\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(\"Write a 20 words description for the following company: {company_name}\")\n",
    "\n",
    "describe_chain = LLMChain(llm=describe_bot, prompt=prompt_template)\n",
    "\n",
    "\n",
    "# simple sequential chain executes a pipeline tasks where each step has only one input and one output\n",
    "# product name --[recom chain]--> company_name --[describe chain]--> description\n",
    "seq_chain = SimpleSequentialChain(chains=[recom_chain, describe_chain], verbose=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m\"Burger Bliss\" or \"Cheezy Cravings\"\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m\"Burger Bliss\" is a mouthwatering haven for burger enthusiasts, offering a delectable range of juicy, flavorful burgers and sides.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The description for the company who makes cheeze burger is:\n",
      "\"Burger Bliss\" is a mouthwatering haven for burger enthusiasts, offering a delectable range of juicy, flavorful burgers and sides.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mThe best name to describe a company that makes Chinese food could be \"Wok 'n Roll,\" as it incorporates a play on words with the popular cooking utensil, the wok, and the phrase \"rock 'n roll,\" adding a fun and catchy element that represents both the cuisine and the energy of the brand.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m\"Wok 'n Roll: A vibrant and playful Chinese food company that combines the essence of rock 'n roll with delicious cuisine.\"\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The description for the company who makes chinese food is:\n",
      "\"Wok 'n Roll: A vibrant and playful Chinese food company that combines the essence of rock 'n roll with delicious cuisine.\"\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mThere are several possible options for a company name that makes women's shoes. Here are a few ideas:\n",
      "\n",
      "1. SoleSophistication\n",
      "2. LadyLuxury Footwear\n",
      "3. Enchant Shoes\n",
      "4. FeminaFancy Footwear\n",
      "5. BellaSoles\n",
      "6. FeminineFootwear\n",
      "7. HeavenlyHeels\n",
      "8. ElegantStep Shoes\n",
      "9. GlamourGait\n",
      "10. ChicSole Company\n",
      "\n",
      "Ultimately, the best name will depend on the brand's desired image, target audience, and specific positioning in the market. It's important to choose a name that resonates with the company's values and reflects the essence of their products.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mA company that specializes in women's shoes, offering options like SoleSophistication, LadyLuxury Footwear, and Enchant Shoes.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The description for the company who makes woman shoes is:\n",
      "A company that specializes in women's shoes, offering options like SoleSophistication, LadyLuxury Footwear, and Enchant Shoes.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mThere are many potential names that could describe a company that makes AI robots, depending on the desired branding and marketing strategy. Here are a few suggestions:\n",
      "\n",
      "1. RoboGenius\n",
      "2. AItronix\n",
      "3. RoboTech\n",
      "4. Synthobotics\n",
      "5. IntelliRobo\n",
      "6. RoboticAI\n",
      "7. SmartBots\n",
      "8. AI Robotics Inc.\n",
      "9. RoboInnovators\n",
      "10. TechnoBots\n",
      "\n",
      "It's important to note that the best name will ultimately depend on the specific goals and target audience of the company, as well as its desired brand image.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mA company that specializes in creating AI robots, offering innovative solutions for various industries and sectors.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The description for the company who makes ai robot is:\n",
      "A company that specializes in creating AI robots, offering innovative solutions for various industries and sectors.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    product = input(\"Enter a product (enter 'quit' to exit): \")\n",
    "    if product == \"quit\": break\n",
    "    print(f\"The description for the company who makes {product} is:\\n{seq_chain.run(product)}\") # run() has to be called with only one exact output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step3.3 use sequential chain to run more complicated cooperative tasks end-to-end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "lang_bot = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.5)\n",
    "\n",
    "# chain 1: review --> english review\n",
    "translate_prompt = ChatPromptTemplate.from_template(\"Translate the following Chinese review to English: \\n\\n{review}\")\n",
    "translate_chain = LLMChain(llm=lang_bot, prompt=translate_prompt, output_key=\"english_review\")\n",
    "\n",
    "# chain 2: english review --> summarized review\n",
    "summarize_prompt = ChatPromptTemplate.from_template(\"Summarize the following review in one sentence: \\n\\n{english_review}\")\n",
    "summarize_chain = LLMChain(llm=lang_bot, prompt=summarize_prompt, output_key=\"summarized_review\")\n",
    "\n",
    "# chain 3: review --> language\n",
    "langclass_prompt = ChatPromptTemplate.from_template(\"What language is the following review: \\n\\n{review}\")\n",
    "langclass_chain = LLMChain(llm=lang_bot, prompt=langclass_prompt, output_key=\"language\")\n",
    "\n",
    "# chain 4: summarized review --> follow up response\n",
    "response_prompt = ChatPromptTemplate.from_template(\"Write a follow up response to the following review in the specific language: \\n\\nSummary:{summarized_review}\\n\\nLanguage:{language}\")\n",
    "response_chain = LLMChain(llm=lang_bot, prompt=response_prompt, output_key=\"followup_response\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequential chain: \n",
    "#  review --[translate chain]--> english review --[summarized chain]--> summarized english review\n",
    "#     |                                                                            |\n",
    "# [language chain]                                                                 |\n",
    "#     v                                                                            v\n",
    "#  specific language ----------------------------------------------------->[response review]--> follow up response in the specific language\n",
    "review_seq_chain = SequentialChain(\n",
    "    chains=[translate_chain, summarize_chain, langclass_chain, response_chain],\n",
    "    input_variables=['review'],\n",
    "    output_variables=['english_review', 'summarized_review', 'followup_response'], # multi output\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Output variable dict: {'review': '', 'english_review': 'The hygiene conditions of this restaurant are good, the variety of dishes is complete, they pay attention to the presentation, and the taste is authentic. I will visit frequently in the future.', 'summarized_review': 'The reviewer praises the restaurant for its cleanliness, wide selection of dishes, attention to presentation, and authentic taste, expressing their intention to visit frequently.', 'followup_response': ''}\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    review = input(\"Enter a Chinese restaurant review (enter 'quit' to exit): \") # \n",
    "    if review == \"quit\": break\n",
    "    print(f\"Output variable dict: {review_seq_chain(review)}\") # just __call__, do not use run() since there're not only one output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step3.4 use router chain to select different paths of chains for different tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_template = \"\"\"You are a very smart physics professor. \\\n",
    "You are great at answering questions about physics in a concise\\\n",
    "and easy to understand manner. \\\n",
    "When you don't know the answer to a question you admit\\\n",
    "that you don't know.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "math_template = \"\"\"You are a very good mathematician. \\\n",
    "You are great at answering math questions. \\\n",
    "You are so good because you are able to break down \\\n",
    "hard problems into their component parts,\n",
    "answer the component parts, and then put them together\\\n",
    "to answer the broader question.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "history_template = \"\"\"You are a very good historian. \\\n",
    "You have an excellent knowledge of and understanding of people,\\\n",
    "events and contexts from a range of historical periods. \\\n",
    "You have the ability to think, reflect, debate, discuss and \\\n",
    "evaluate the past. You have a respect for historical evidence\\\n",
    "and the ability to make use of it to support your explanations \\\n",
    "and judgements.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "computerscience_template = \"\"\" You are a successful computer scientist.\\\n",
    "You have a passion for creativity, collaboration,\\\n",
    "forward-thinking, confidence, strong problem-solving capabilities,\\\n",
    "understanding of theories and algorithms, and excellent communication \\\n",
    "skills. You are great at answering coding questions. \\\n",
    "You are so good because you know how to solve a problem by \\\n",
    "describing the solution in imperative steps \\\n",
    "that a machine can easily interpret and you know how to \\\n",
    "choose a solution that has a good balance between \\\n",
    "time complexity and space complexity.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"physics\",\n",
    "        \"description\": \"Good for answering questions about physics\",\n",
    "        \"prompt_template\": physics_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"math\",\n",
    "        \"description\": \"Good for answering math questions\",\n",
    "        \"prompt_template\": math_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"History\",\n",
    "        \"description\": \"Good for answering history questions\",\n",
    "        \"prompt_template\": history_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"computer science\",\n",
    "        \"description\": \"Good for answering computer science questions\",\n",
    "        \"prompt_template\": computerscience_template\n",
    "    }\n",
    "]\n",
    "\n",
    "expert_bot = ChatOpenAI(model='gpt-3.5-turbo', temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "physics: Good for answering questions about physics\n",
      "math: Good for answering math questions\n",
      "History: Good for answering history questions\n",
      "computer science: Good for answering computer science questions\n"
     ]
    }
   ],
   "source": [
    "# define destination chains and destination string for the router to choose from\n",
    "dest_chains = {}\n",
    "for prompt_info in prompt_infos:\n",
    "    prompt_template = ChatPromptTemplate.from_template(template=prompt_info['prompt_template'])\n",
    "    dest_chain = LLMChain(llm=expert_bot, prompt=prompt_template)\n",
    "    dest_chains[prompt_info['name']] = dest_chain\n",
    "    \n",
    "dest_str = \"\\n\".join([f\"{pi['name']}: {pi['description']}\" for pi in prompt_infos])\n",
    "print(dest_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have to add another default destination chain in case of unexpected tasks\n",
    "default_prompt = ChatPromptTemplate.from_template(\"{input}\")\n",
    "default_dest_chain = LLMChain(llm=expert_bot, prompt=default_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given a raw text input to a language model select the model prompt best suited for the input. You will be given the names of the available prompts and a description of what the prompt is best suited for. You may also revise the original input if you think that revising it will ultimately lead to a better response from the language model.\n",
      "\n",
      "<< FORMATTING >>\n",
      "Return a markdown code snippet with a JSON object formatted to look like:\n",
      "```json\n",
      "{{\n",
      "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
      "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
      "}}\n",
      "```\n",
      "\n",
      "REMEMBER: \"destination\" MUST be one of the candidate prompt names specified below OR it can be \"DEFAULT\" if the input is not well suited for any of the candidate prompts.\n",
      "REMEMBER: \"next_inputs\" can just be the original input if you don't think any modifications are needed.\n",
      "\n",
      "<< CANDIDATE PROMPTS >>\n",
      "physics: Good for answering questions about physics\n",
      "math: Good for answering math questions\n",
      "History: Good for answering history questions\n",
      "computer science: Good for answering computer science questions\n",
      "\n",
      "<< INPUT >>\n",
      "{input}\n",
      "\n",
      "<< OUTPUT (must include ```json at the start of the response) >>\n",
      "<< OUTPUT (must end with ```) >>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define the router prompt template to provide the destinations to the router\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.router.llm_router import RouterOutputParser\n",
    "from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE\n",
    "\n",
    "multi_prompt_router_template_str = MULTI_PROMPT_ROUTER_TEMPLATE.format(destinations=dest_str)\n",
    "\n",
    "router_prompt_template = PromptTemplate(template=multi_prompt_router_template_str, \n",
    "                                        input_variables=[\"input\"], \n",
    "                                        output_parser=RouterOutputParser())\n",
    "\n",
    "print(multi_prompt_router_template_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.router.llm_router import LLMRouterChain\n",
    "\n",
    "# define the router chain and combine it with all of the destination chains to a multi prompt chain\n",
    "router_chain = LLMRouterChain.from_llm(llm=expert_bot, prompt=router_prompt_template)\n",
    "\n",
    "expert_chain = MultiPromptChain(router_chain=router_chain,\n",
    "                        destination_chains=dest_chains,\n",
    "                        default_chain=default_dest_chain,\n",
    "                        verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "physics: {'input': 'What is black body radiation?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The answer from the expert is:\n",
      "Black body radiation refers to the electromagnetic radiation emitted by an object that absorbs all incident radiation and reflects or transmits none. It is called \"black body\" because it absorbs all wavelengths of light, appearing black at room temperature. \n",
      "\n",
      "According to Planck's law, black body radiation is characterized by a continuous spectrum of wavelengths and intensities, which depend on the temperature of the object. As the temperature increases, the peak intensity of the radiation shifts to shorter wavelengths, resulting in a change in color from red to orange, yellow, white, and eventually blue at very high temperatures.\n",
      "\n",
      "Black body radiation is a fundamental concept in physics and has significant applications in various fields, including astrophysics, thermodynamics, and quantum mechanics. It played a crucial role in the development of quantum theory and understanding the behavior of light and matter.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "math: {'input': 'what is the solution of the equation: {x + y = 1, x - 2y = -2}'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The answer from the expert is:\n",
      "To find the solution of the given system of equations, we can use the method of substitution or elimination. Let's solve it using the elimination method:\n",
      "\n",
      "1. Start with the system of equations:\n",
      "   x + y = 1   ...(Equation 1)\n",
      "   x - 2y = -2  ...(Equation 2)\n",
      "\n",
      "2. Multiply Equation 1 by 2 to make the coefficients of y in both equations equal:\n",
      "   2(x + y) = 2(1)\n",
      "   2x + 2y = 2   ...(Equation 3)\n",
      "\n",
      "3. Now, subtract Equation 2 from Equation 3 to eliminate the variable x:\n",
      "   (2x + 2y) - (x - 2y) = 2 - (-2)\n",
      "   2x + 2y - x + 2y = 2 + 2\n",
      "   x + 4y = 4   ...(Equation 4)\n",
      "\n",
      "4. We now have a new equation, Equation 4, which only involves the variables x and y. Let's solve it for one variable:\n",
      "\n",
      "   From Equation 1, we have:\n",
      "   x = 1 - y\n",
      "\n",
      "5. Substitute the value of x in Equation 4 with 1 - y:\n",
      "   (1 - y) + 4y = 4\n",
      "   1 - y + 4y = 4\n",
      "   1 + 3y = 4\n",
      "\n",
      "6. Solve for y:\n",
      "   3y = 4 - 1\n",
      "   3y = 3\n",
      "   y = 1\n",
      "\n",
      "7. Substitute the value of y back into Equation 1 to find x:\n",
      "   x + 1 = 1\n",
      "   x = 1 - 1\n",
      "   x = 0\n",
      "\n",
      "8. Therefore, the solution to the given system of equations is x = 0 and y = 1.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "History: {'input': 'What was the impact of the Great Recession on the U.S. economy?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The answer from the expert is:\n",
      "Thank you for your kind words. As a historian, I can provide an analysis of the impact of the Great Recession on the U.S. economy.\n",
      "\n",
      "The Great Recession, which began in 2008 and lasted until 2009, had a profound impact on the U.S. economy. It was triggered by the bursting of the housing bubble, which led to a financial crisis and subsequent economic downturn. Here are some key impacts:\n",
      "\n",
      "1. Unemployment: One of the most significant consequences of the Great Recession was a sharp increase in unemployment rates. Many businesses faced financial difficulties and were forced to lay off workers or reduce their workforce. The unemployment rate reached a peak of 10% in October 2009, causing significant hardship for millions of Americans.\n",
      "\n",
      "2. Housing Market Collapse: The recession was primarily fueled by the collapse of the housing market. Many individuals and families faced foreclosure as they were unable to meet their mortgage payments. This led to a decline in housing prices, which further exacerbated the economic downturn.\n",
      "\n",
      "3. Financial Sector Crisis: The recession exposed weaknesses in the financial sector, particularly in the banking industry. Major financial institutions faced insolvency or severe financial strain, leading to government interventions such as bailouts and the Troubled Asset Relief Program (TARP). The crisis also resulted in stricter regulations and reforms to prevent a similar situation in the future.\n",
      "\n",
      "4. Stock Market Decline: The stock market experienced a significant decline during the Great Recession. The Dow Jones Industrial Average, a key indicator of stock market performance, lost over 50% of its value between 2007 and 2009. This had a negative impact on investor confidence and further contributed to the economic downturn.\n",
      "\n",
      "5. Government Response: In response to the crisis, the U.S. government implemented various measures to stimulate the economy and stabilize financial markets. These included the American Recovery and Reinvestment Act, which aimed to create jobs and invest in infrastructure projects. The Federal Reserve also implemented monetary policies, such as lowering interest rates and quantitative easing, to encourage borrowing and spending.\n",
      "\n",
      "6. Long-Term Effects: The Great Recession had long-lasting effects on the U.S. economy. It resulted in a slow and uneven recovery, with many individuals and businesses struggling to regain their pre-recession financial stability. The recession also highlighted structural issues within the economy, such as income inequality and the decline of manufacturing industries.\n",
      "\n",
      "Overall, the Great Recession had a significant and lasting impact on the U.S. economy. It exposed vulnerabilities in the financial system, led to widespread unemployment and foreclosures, and resulted in a slow recovery. The lessons learned from this crisis have influenced economic policies and regulations to mitigate the risk of future economic downturns.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "computer science: {'input': 'How does the Internet work?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The answer from the expert is:\n",
      "The Internet is a global network of interconnected computers and devices that communicate with each other using a standardized set of protocols. It allows for the exchange of information and data across vast distances.\n",
      "\n",
      "At a high level, the Internet works through a combination of hardware, software, and network protocols. Here is a simplified explanation of the key components and steps involved:\n",
      "\n",
      "1. Devices and Infrastructure: The Internet relies on a vast network of physical infrastructure, including routers, switches, servers, and data centers. These devices are connected through various means, such as fiber optic cables, satellite links, or wireless connections.\n",
      "\n",
      "2. IP Addresses: Every device connected to the Internet is assigned a unique identifier called an IP (Internet Protocol) address. IP addresses can be either IPv4 (32-bit) or IPv6 (128-bit) and are used to identify and locate devices on the network.\n",
      "\n",
      "3. Protocols: The Internet operates based on a set of protocols, which are rules and standards that govern how data is transmitted and received. The most fundamental protocol is the Internet Protocol (IP), which provides the addressing and routing mechanism. Other important protocols include Transmission Control Protocol (TCP) for reliable data transmission, User Datagram Protocol (UDP) for faster but unreliable transmission, and Hypertext Transfer Protocol (HTTP) for web communication.\n",
      "\n",
      "4. Packet Switching: When data is sent over the Internet, it is divided into smaller units called packets. Each packet contains the source and destination IP addresses, as well as the actual data being transmitted. These packets are then routed independently across the network, taking different paths based on the current network conditions. This process is known as packet switching.\n",
      "\n",
      "5. Routing: Routers play a crucial role in the Internet's functioning. They examine the destination IP address of each packet and determine the most efficient path to forward it towards its destination. Routers exchange routing information with each other to build a dynamic map of the network, allowing them to make intelligent routing decisions.\n",
      "\n",
      "6. Transmission: Once the packets reach their destination, they are reassembled into the original data stream. This process occurs at the receiving device, which could be a computer, smartphone, or any other Internet-enabled device.\n",
      "\n",
      "7. Application Layer: On top of the underlying protocols, various application layer protocols enable specific services and applications to function over the Internet. Examples include HTTP for web browsing, SMTP for email, FTP for file transfer, and many more.\n",
      "\n",
      "Overall, the Internet works by breaking down data into packets, routing them across the network, and reassembling them at the destination. This decentralized and distributed architecture allows for robust and efficient communication between devices worldwide.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "None: {'input': 'Why does every cell in the body contain DNA?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The answer from the expert is:\n",
      "Every cell in the body contains DNA because DNA is the genetic material that carries the instructions for the development, functioning, and reproduction of all living organisms. DNA contains the information necessary for the synthesis of proteins, which are essential for the structure and function of cells. It serves as a blueprint for the production of specific proteins that determine the characteristics and functions of each cell type. Additionally, DNA is also responsible for the inheritance of traits from one generation to the next. Therefore, every cell in the body contains DNA to ensure the proper functioning and development of the organism.\n"
     ]
    }
   ],
   "source": [
    "# physics question: What is black body radiation?\n",
    "# math question: what is the solution of the equation: {x + y = 1, x - 2y = -2}\n",
    "# history question: What was the impact of the Great Recession on the U.S. economy?\n",
    "# computer science question: How does the Internet work?\n",
    "# biology question: Why does every cell in the body contain DNA? (destination: None, to use the default chain)\n",
    "while True:\n",
    "    domain_specific_question = input(\"Enter a domain-specific question (enter 'quit' to exit): \")\n",
    "    if domain_specific_question == \"quit\": break\n",
    "    print(f\"The answer from the expert is:\\n{expert_chain.run(domain_specific_question)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step4.1 use doc similary search to retrieve relative docs in the local document to implement RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the local document used below can be downloaded at: [here](https://github.com/research-outcome/llm-langchain-examples/blob/main/OutdoorClothingCatalog_1000.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\": 0\\nname: Women's Campside Oxfords\\ndescription: This ultracomfortable lace-to-toe Oxford boasts a super-soft canvas, thick cushioning, and quality construction for a broken-in feel from the first time you put them on. \\n\\nSize & Fit: Order regular shoe size. For half sizes not offered, order up to next whole size. \\n\\nSpecs: Approx. weight: 1 lb.1 oz. per pair. \\n\\nConstruction: Soft canvas material for a broken-in feel and look. Comfortable EVA innersole with Cleansport NXT antimicrobial odor control. Vintage hunt, fish and camping motif on innersole. Moderate arch contour of innersole. EVA foam midsole for cushioning and support. Chain-tread-inspired molded rubber outsole with modified chain-tread pattern. Imported. \\n\\nQuestions? Please contact us for any inquiries.\", metadata={'source': './data/OutdoorClothingCatalog_1000.csv', 'row': 0}),\n",
       " Document(page_content=': 1\\nname: Recycled Waterhog Dog Mat, Chevron Weave\\ndescription: Protect your floors from spills and splashing with our ultradurable recycled Waterhog dog mat made right here in the USA. \\n\\nSpecs\\nSmall - Dimensions: 18\" x 28\". \\nMedium - Dimensions: 22.5\" x 34.5\".\\n\\nWhy We Love It\\nMother nature, wet shoes and muddy paws have met their match with our Recycled Waterhog mats. Ruggedly constructed from recycled plastic materials, these ultratough mats help keep dirt and water off your floors and plastic out of landfills, trails and oceans. Now, that\\'s a win-win for everyone.\\n\\nFabric & Care\\nVacuum or hose clean.\\n\\nConstruction\\n24 oz. polyester fabric made from 94% recycled materials.\\nRubber backing.\\n\\nAdditional Features\\nFeatures an -exclusive design.\\nFeatures thick and thin fibers for scraping dirt and absorbing water.\\nDries quickly and resists fading, rotting, mildew and shedding.\\nUse indoors or out.\\nMade in the USA.\\n\\nHave questions? Reach out to our customer service team with any questions you may have.', metadata={'source': './data/OutdoorClothingCatalog_1000.csv', 'row': 1}),\n",
       " Document(page_content=\": 2\\nname: Infant and Toddler Girls' Coastal Chill Swimsuit, Two-Piece\\ndescription: She'll love the bright colors, ruffles and exclusive whimsical prints of this toddler's two-piece swimsuit! Our four-way-stretch and chlorine-resistant fabric keeps its shape and resists snags. The UPF 50+ rated fabric provides the highest rated sun protection possible, blocking 98% of the sun's harmful rays. The crossover no-slip straps and fully lined bottom ensure a secure fit and maximum coverage. Machine wash and line dry for best results. Imported.\", metadata={'source': './data/OutdoorClothingCatalog_1000.csv', 'row': 2}),\n",
       " Document(page_content=\": 3\\nname: Refresh Swimwear, V-Neck Tankini Contrasts\\ndescription: Whether you're going for a swim or heading out on an SUP, this watersport-ready tankini top is designed to move with you and stay comfortable. All while looking great in an eye-catching colorblock style. \\n\\nSize & Fit\\nFitted: Sits close to the body.\\n\\nWhy We Love It\\nNot only does this swimtop feel good to wear, its fabric is good for the earth too. In recycled nylon, with Lycra spandex for the perfect amount of stretch. \\n\\nFabric & Care\\nThe premium Italian-blend is breathable, quick drying and abrasion resistant. \\nBody in 82% recycled nylon with 18% Lycra spandex. \\nLined in 90% recycled nylon with 10% Lycra spandex. \\nUPF 50+ rated  the highest rated sun protection possible. \\nHandwash, line dry.\\n\\nAdditional Features\\nLightweight racerback straps are easy to get on and off, and won't get in your way. \\nFlattering V-neck silhouette. \\nImported.\\n\\nSun Protection That Won't Wear Off\\nOur high-performance fabric provides SPF\", metadata={'source': './data/OutdoorClothingCatalog_1000.csv', 'row': 3}),\n",
       " Document(page_content=\": 4\\nname: EcoFlex 3L Storm Pants\\ndescription: Our new TEK O2 technology makes our four-season waterproof pants even more breathable. It's guaranteed to keep you dry and comfortable  whatever the activity and whatever the weather. Size & Fit: Slightly Fitted through hip and thigh. \\n\\nWhy We Love It: Our state-of-the-art TEK O2 technology offers the most breathability we've ever tested. Great as ski pants, they're ideal for a variety of outdoor activities year-round. Plus, they're loaded with features outdoor enthusiasts appreciate, including weather-blocking gaiters and handy side zips. Air In. Water Out. See how our air-permeable TEK O2 technology keeps you dry and comfortable. \\n\\nFabric & Care: 100% nylon, exclusive of trim. Machine wash and dry. \\n\\nAdditional Features: Three-layer shell delivers waterproof protection. Brand new TEK O2 technology provides enhanced breathability. Interior gaiters keep out rain and snow. Full side zips for easy on/off over boots. Two zippered hand pockets. Thigh pocket. Imported.\\n\\n  Official Supplier to the U.S. Ski Team\\nTHEIR WILL\", metadata={'source': './data/OutdoorClothingCatalog_1000.csv', 'row': 4}),\n",
       " Document(page_content=\": 5\\nname: Smooth Comfort Check Shirt, Slightly Fitted\\ndescription: Our men's slightly fitted check shirt is the perfect choice for your wardrobe! Customers love how it fits right out of the dryer. Size & Fit: Slightly Fitted, Relaxed through the chest and sleeve with a slightly slimmer waist. Fabric & Care: 100% cotton poplin, with wrinkle-free performance that won't wash out. Our innovative TrueCool fabric wicks moisture away from your skin and helps it dry quickly. Additional Features: Traditional styling with a button-down collar and a single patch pocket. Imported.\", metadata={'source': './data/OutdoorClothingCatalog_1000.csv', 'row': 5}),\n",
       " Document(page_content=': 6\\nname: Mens Outdoor Research Apex Gloves\\ndescription: These Outdoor Research Arete gloves are perfect for your backcountry adventures. They feature a tough Taslan nylon shell and removable Gore-Tex nylon fleece liner that is quick-drying and provides complete protection and warmth. The stretchy nylon Lycra elastane soft-shell fabric on the back of the hands allows for freedom of movement, while the ergonomic design lets your hands move naturally for maximum comfort. The gauntlet closure seals out snow and cold wind, and a special pocket allows for a heat pack to be inserted to help keep your hands warm. Both the shell and 100-weight-fleece liner can be worn alone or together for maximum warmth. Imported. These gloves also offer serious waterproof protection from the elements, and are highly breathable to allow moisture vapor to escape. Get the durability you expect from Gore-Tex fabrics.', metadata={'source': './data/OutdoorClothingCatalog_1000.csv', 'row': 6}),\n",
       " Document(page_content=\": 7\\nname: Women's Ultraplush Sweats, Relaxed Crewneck\\ndescription: This crewneck sweatshirt is crafted from soft french terry, making it feel great after a long day. It also looks so good it could be worn around town. Our most generous fit sits farthest from the body and falls at the hip. It's made of 95% cotton and 5% spandex and is a substantial midweight french terry fabric, smooth on the outside and softly looped on the inside. It's designed with shaping for a flattering, feminine fit and features raglan sleeves, a straight hem with side slits, and a curved hem that's slightly longer in the back. Machine wash and dry. Imported.\", metadata={'source': './data/OutdoorClothingCatalog_1000.csv', 'row': 7}),\n",
       " Document(page_content=': 8\\nname: Mountain Man Fleece Jacket\\ndescription: Our best-value fleece jacket is designed with inspiration from our archives and made from 100% recycled polyester for unbeatable comfort and wear-anywhere style. \\n\\nSize & Fit: Slightly Fitted. Best with lightweight layer. Falls at hip. \\n\\nWhy We Love It: Our designers took inspiration from the  archives to create this ultrasoft fleece jacket. We love how the heritage styling is updated with a modern, slimming fit. Plus, its made from 100% recycled fleece  so you can stay warm and feel good about it. \\n\\nFabric & Care: 100% recycled fleece is soft, cozy and gentle on the planet. Ultraplush fibers resist wind for even more warmth. Machine wash and dry. \\n\\nAdditional Features: Features our classic Mount Katahdin logo. Bart Boot lace-inspired zippers and drawcord. Two lower zippered hand pockets. Elastic cuffs and drawcord hem seal out cold air. Imported.', metadata={'source': './data/OutdoorClothingCatalog_1000.csv', 'row': 8}),\n",
       " Document(page_content=': 9\\nname: Compact Camping Table, 25\"\\ndescription: This aluminum portable camp table is perfect for car camping trips, picnics and tailgates. It features a one-piece design with telescoping legs that folds down into a small package. The table is made from lightweight yet durable aluminum and can hold up to 60 lb. The open dimensions are 25\"H x 25\"W x 27.5\"D and the folded dimensions are 25\"H x 24\"W x 2\"D, and the weight is 5 lb. 10 oz. This table can accommodate dinner for up to four people or can be used as a side table.', metadata={'source': './data/OutdoorClothingCatalog_1000.csv', 'row': 9})]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import CSVLoader\n",
    "\n",
    "# load the local document into a list of page contexts\n",
    "local_doc_path = './data/OutdoorClothingCatalog_1000.csv'\n",
    "loader = CSVLoader(file_path=local_doc_path)\n",
    "docs = loader.load()\n",
    "docs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0033516422561036653,\n",
       " 0.0013535809364467399,\n",
       " 0.024042216664436226,\n",
       " -0.03267204960747905,\n",
       " -0.006820462594368705,\n",
       " 0.01356510435066906,\n",
       " -0.030356056976786578,\n",
       " 0.004649218921017868,\n",
       " -0.015219385732486313,\n",
       " -0.015439956459218928]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings() # use openai embeddings to embed the text\n",
    "\n",
    "query = \"Please list all your shirts with sun protection in a table in markdown and summarize each one.\"\n",
    "\n",
    "embed = embeddings.embed_query(query)\n",
    "print(len(embed))\n",
    "embed[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Document(page_content=\": 618\\nname: Men's Tropical Plaid Short-Sleeve Shirt\\ndescription: Our lightest hot-weather shirt is rated UPF 50+ for superior protection from the sun's UV rays. With a traditional fit that is relaxed through the chest, sleeve, and waist, this fabric is made of 100% polyester and is wrinkle-resistant. With front and back cape venting that lets in cool breezes and two front bellows pockets, this shirt is imported and provides the highest rated sun protection possible. \\n\\nSun Protection That Won't Wear Off. Our high-performance fabric provides SPF 50+ sun protection, blocking 98% of the sun's harmful rays.\", metadata={'source': './data/OutdoorClothingCatalog_1000.csv', 'row': 618})"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "\n",
    "# use the openai embeddings to embed the local document and search the similar documents with the query\n",
    "db = DocArrayInMemorySearch.from_documents(docs, embeddings)\n",
    "relative_docs = db.similarity_search(query)\n",
    "print(len(relative_docs))\n",
    "relative_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      ": 618\n",
      "name: Men's Tropical Plaid Short-Sleeve Shirt\n",
      "description: Our lightest hot-weather shirt is rated UPF 50+ for superior protection from the sun's UV rays. With a traditional fit that is relaxed through the chest, sleeve, and waist, this fabric is made of 100% polyester and is wrinkle-resistant. With front and back cape venting that lets in cool breezes and two front bellows pockets, this shirt is imported and provides the highest rated sun protection possible. \n",
      "\n",
      "Sun Protection That Won't Wear Off. Our high-performance fabric provides SPF 50+ sun protection, blocking 98% of the sun's harmful rays.\n"
     ]
    }
   ],
   "source": [
    "# or use db as retriever\n",
    "retriever = db.as_retriever()\n",
    "retrieved_docs = retriever.invoke(query)\n",
    "print(len(retrieved_docs))\n",
    "print(retrieved_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2934\n",
      "Context: : 618\n",
      "name: Men's Tropical Plaid Short-Sleeve Shirt\n",
      "description: Our lightest hot-weather shirt is rated UPF 50+ for superior protection from the sun's UV rays. With a traditional fit that is relaxed through the chest, sleeve, and waist, this fabric is made of 100% polyester and is wrinkle-resistant. With front and back cape venting that lets in cool breezes and two front bellows pockets, this shirt is imported and provides the highest rated sun protection possible. \n",
      "\n",
      "Sun Protection That Won't Wear Off. Our high-performance fabric provides SPF 50+ sun protection, blocking 98% of the sun's harmful rays.: 374\n",
      "name: Men's Plaid Tropic Shirt, Short-Sleeve\n",
      "description: Our Ultracomfortable sun protection is rated to UPF 50+, helping you stay cool and dry. Originally designed for fishing, this lightest hot-weather shirt offers UPF 50+ coverage and is great for extended travel. SunSmart technology blocks 98% of the sun's harmful UV rays, while the high-performance fabric is wrinkle-free and quickly evaporates perspiration. Made with 52% polyester and 48% nylon, this shirt is machine washable and dryable. Additional features include front and back cape venting, two front bellows pockets and an imported design. With UPF 50+ coverage, you can limit sun exposure and feel secure with the highest rated sun protection available.: 535\n",
      "name: Men's TropicVibe Shirt, Short-Sleeve\n",
      "description: This Mens sun-protection shirt with built-in UPF 50+ has the lightweight feel you want and the coverage you need when the air is hot and the UV rays are strong. Size & Fit: Traditional Fit: Relaxed through the chest, sleeve and waist. Fabric & Care: Shell: 71% Nylon, 29% Polyester. Lining: 100% Polyester knit mesh. UPF 50+ rated  the highest rated sun protection possible. Machine wash and dry. Additional Features: Wrinkle resistant. Front and back cape venting lets in cool breezes. Two front bellows pockets. Imported.\n",
      "\n",
      "Sun Protection That Won't Wear Off: Our high-performance fabric provides SPF 50+ sun protection, blocking 98% of the sun's harmful rays.: 255\n",
      "name: Sun Shield Shirt by\n",
      "description: \"Block the sun, not the fun  our high-performance sun shirt is guaranteed to protect from harmful UV rays. \n",
      "\n",
      "Size & Fit: Slightly Fitted: Softly shapes the body. Falls at hip.\n",
      "\n",
      "Fabric & Care: 78% nylon, 22% Lycra Xtra Life fiber. UPF 50+ rated  the highest rated sun protection possible. Handwash, line dry.\n",
      "\n",
      "Additional Features: Wicks moisture for quick-drying comfort. Fits comfortably over your favorite swimsuit. Abrasion resistant for season after season of wear. Imported.\n",
      "\n",
      "Sun Protection That Won't Wear Off\n",
      "Our high-performance fabric provides SPF 50+ sun protection, blocking 98% of the sun's harmful rays. This fabric is recommended by The Skin Cancer Foundation as an effective UV protectant.\n",
      "\n",
      "Question: Please list all your shirts with sun protection in a table in markdown and summarize each one.\n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "# the native way to get the answer by manually feed the retrieved relative docs into the context and append the query\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "rag_bot = OpenAI(temperature=0.0, model='gpt-3.5-turbo-instruct')\n",
    "\n",
    "context = \"\".join([doc.page_content for doc in relative_docs])\n",
    "\n",
    "# prompt_template = ChatPromptTemplate.from_template()\n",
    "# messages = prompt_template.format_messages(context=context, query=query)\n",
    "# print(len(messages[0].content))\n",
    "# response = rag_bot(messages=messages)\n",
    "# print(response)\n",
    "\n",
    "final_input = f\"Context: {context}\\n\\nQuestion: {query}\\nAnswer:\"\n",
    "print(len(final_input))\n",
    "print(final_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "| Name | Description | Sun Protection Rating |\n",
       "| --- | --- | --- |\n",
       "| Men's Tropical Plaid Short-Sleeve Shirt | Made of 100% polyester, this shirt is rated UPF 50+ for superior protection from the sun's UV rays. It features front and back cape venting and two front bellows pockets. | SPF 50+ |\n",
       "| Men's Plaid Tropic Shirt, Short-Sleeve | Made with 52% polyester and 48% nylon, this shirt offers UPF 50+ coverage and is great for extended travel. It also features front and back cape venting and two front bellows pockets. | SPF 50+ |\n",
       "| Men's TropicVibe Shirt, Short-Sleeve | Made of 71% nylon and 29% polyester, this shirt has built-in UPF 50+ and front and back cape venting. It also has two front bellows pockets and is wrinkle-resistant. | SPF 50+ |\n",
       "| Sun Shield Shirt | Made of 78% nylon and 22% Lycra Xtra Life fiber, this shirt has UPF 50+ and is designed to be worn over a swimsuit. It is also moisture-wicking and abrasion-resistant"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "response = rag_bot.invoke(final_input)\n",
    "Markdown(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step4.2 altenatively, use retrievalQA built-in chain in langchain to save the efforts to construct context manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "| Name | Description | Sun Protection Rating |\n",
       "| --- | --- | --- |\n",
       "| Men's Tropical Plaid Short-Sleeve Shirt | Made of 100% polyester, UPF 50+ rated, wrinkle-resistant, front and back cape venting, two front bellows pockets, imported | SPF 50+, blocks 98% of harmful UV rays |\n",
       "| Men's Plaid Tropic Shirt, Short-Sleeve | Made of 52% polyester and 48% nylon, UPF 50+ rated, SunSmart technology blocks 98% of harmful UV rays, wrinkle-free, front and back cape venting, two front bellows pockets, imported | SPF 50+, blocks 98% of harmful UV rays |\n",
       "| Men's TropicVibe Shirt, Short-Sleeve | Made of 71% nylon and 29% polyester, UPF 50+ rated, front and back cape venting, two front bellows pockets, imported | SPF 50+, blocks 98% of harmful UV rays |\n",
       "| Sun Shield Shirt | Made of 78% nylon and 22% Lycra Xtra Life fiber, UPF 50+ rated, wicks moisture, fits comfortably over swimsuit, abrasion resistant"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=rag_bot, chain_type=\"stuff\", retriever=retriever)\n",
    "response = qa_chain.run(query)\n",
    "Markdown(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step4.3 or simply use vectorstore index end-to-end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "| Name | Description | Sun Protection Rating |\n",
       "| --- | --- | --- |\n",
       "| Men's Tropical Plaid Short-Sleeve Shirt | Made of 100% polyester, UPF 50+ rating, front and back cape venting, two front bellows pockets | SPF 50+, blocks 98% of harmful UV rays |\n",
       "| Men's Plaid Tropic Shirt, Short-Sleeve | Made of 52% polyester and 48% nylon, UPF 50+ rating, front and back cape venting, two front bellows pockets | SPF 50+, blocks 98% of harmful UV rays |\n",
       "| Men's TropicVibe Shirt, Short-Sleeve | Made of 71% nylon and 29% polyester, UPF 50+ rating, front and back cape venting, two front bellows pockets | SPF 50+, blocks 98% of harmful UV rays |\n",
       "| Sun Shield Shirt | Made of 78% nylon and 22% Lycra Xtra Life fiber, UPF 50+ rating, wicks moisture, abrasion resistant | SPF 50+, blocks 98% of harmful UV rays |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "\n",
    "# Alternatively, given a list of loaders to load the docs and transfer them into a vector store with indexs\n",
    "index = VectorstoreIndexCreator(vectorstore_cls=DocArrayInMemorySearch, embedding=embeddings).from_loaders([loader]) \n",
    "response = index.query(query, llm=rag_bot) # search the vector store by cosine similarity, and combine the relative segments as the context with the query to get the answer\n",
    "\n",
    "Markdown(response) # compare with step4.1 step4.2, the answer from vectorstore index is the best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step5.1 generate QA pairs from the local document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.evaluation.qa import QAGenerateChain\n",
    "\n",
    "gen_bot = ChatOpenAI(temperature=0.0, model='gpt-3.5-turbo')\n",
    "gen_chain = QAGenerateChain.from_llm(gen_bot)\n",
    "gen_examples = gen_chain.apply_and_parse([{\"doc\": doc} for doc in retrieved_docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:\n",
      "page_content=\": 618\\nname: Men's Tropical Plaid Short-Sleeve Shirt\\ndescription: Our lightest hot-weather shirt is rated UPF 50+ for superior protection from the sun's UV rays. With a traditional fit that is relaxed through the chest, sleeve, and waist, this fabric is made of 100% polyester and is wrinkle-resistant. With front and back cape venting that lets in cool breezes and two front bellows pockets, this shirt is imported and provides the highest rated sun protection possible. \\n\\nSun Protection That Won't Wear Off. Our high-performance fabric provides SPF 50+ sun protection, blocking 98% of the sun's harmful rays.\" metadata={'source': './data/OutdoorClothingCatalog_1000.csv', 'row': 618}\n",
      "\n",
      "query: What is the rating of the Men's Tropical Plaid Short-Sleeve Shirt for protection from the sun's UV rays?\n",
      "\n",
      "golden answer generated by gen_chain: The Men's Tropical Plaid Short-Sleeve Shirt is rated UPF 50+ for superior protection from the sun's UV rays.\n",
      "\n",
      "predicted answer from qa_chain:  The Men's Tropical Plaid Short-Sleeve Shirt is rated UPF 50+ for superior protection from the sun's UV rays.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Context:\\n{retrieved_docs[0]}\\n\")\n",
    "print(f\"query: {gen_examples[0]['qa_pairs']['query']}\\n\")\n",
    "print(f\"golden answer generated by gen_chain: {gen_examples[0]['qa_pairs']['answer']}\\n\")\n",
    "print(f\"predicted answer from qa_chain: {qa_chain.run(gen_examples[0]['qa_pairs']['query'])}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step5.2 evaluation about the predictions using llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.evaluation.qa import QAEvalChain\n",
    "\n",
    "eval_bot = ChatOpenAI(temperature=0.0, model='gpt-3.5-turbo')\n",
    "eval_chain = QAEvalChain.from_llm(eval_bot)\n",
    "\n",
    "qa_examples = [{'query': example['qa_pairs']['query'], 'answer': example['qa_pairs']['answer']} for example in gen_examples] # a list of qa dict, like [{'query': query, 'answer': answer}, ...]\n",
    "\n",
    "qa_examples.append( # induce a very hard question manually to make llm fail\n",
    "    {'query': 'What is the name of the pants described in the document?',\n",
    "    'answer': 'The name of the pants is EcoFlex 3L Storm Pants.'\n",
    "    }\n",
    ")\n",
    "\n",
    "predictions = qa_chain.apply(qa_examples) # apply() can run() a batch of inputs\n",
    "eval_results = eval_chain.evaluate(qa_examples, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 0:\n",
      "Question: What is the rating of the Men's Tropical Plaid Short-Sleeve Shirt for protection from the sun's UV rays?\n",
      "Real Answer: The Men's Tropical Plaid Short-Sleeve Shirt is rated UPF 50+ for superior protection from the sun's UV rays.\n",
      "Predicted Answer:  The Men's Tropical Plaid Short-Sleeve Shirt is rated UPF 50+ for superior protection from the sun's UV rays.\n",
      "Evaluation Result: CORRECT\n",
      "\n",
      "Example 1:\n",
      "Question: What is the fabric composition of the Men's Plaid Tropic Shirt, Short-Sleeve?\n",
      "Real Answer: The Men's Plaid Tropic Shirt, Short-Sleeve is made with 52% polyester and 48% nylon.\n",
      "Predicted Answer:  The fabric composition of the Men's Plaid Tropic Shirt, Short-Sleeve is 52% polyester and 48% nylon.\n",
      "Evaluation Result: CORRECT\n",
      "\n",
      "Example 2:\n",
      "Question: What is the fabric composition of the Men's TropicVibe Shirt, Short-Sleeve?\n",
      "Real Answer: The fabric composition of the Men's TropicVibe Shirt, Short-Sleeve is 71% Nylon and 29% Polyester.\n",
      "Predicted Answer:  The fabric composition of the Men's TropicVibe Shirt, Short-Sleeve is 71% Nylon and 29% Polyester.\n",
      "Evaluation Result: CORRECT\n",
      "\n",
      "Example 3:\n",
      "Question: What is the fabric composition of the Sun Shield Shirt?\n",
      "Real Answer: The fabric composition of the Sun Shield Shirt is 78% nylon and 22% Lycra Xtra Life fiber.\n",
      "Predicted Answer:  The fabric composition of the Sun Shield Shirt is 78% nylon and 22% Lycra Xtra Life fiber.\n",
      "Evaluation Result: CORRECT\n",
      "\n",
      "Example 4:\n",
      "Question: What is the name of the pants described in the document?\n",
      "Real Answer: The name of the pants is EcoFlex 3L Storm Pants.\n",
      "Predicted Answer:  The name of the pants described in the document is \"Athletic Boot-Legs.\"\n",
      "Evaluation Result: INCORRECT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, eg in enumerate(qa_examples):\n",
    "    print(f\"Example {i}:\")\n",
    "    print(\"Question: \" + predictions[i]['query'])\n",
    "    print(\"Real Answer: \" + predictions[i]['answer'])\n",
    "    print(\"Predicted Answer: \" + predictions[i]['result'])\n",
    "    print(\"Evaluation Result: \" + eval_results[i]['results'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step6.1 build an agent to use built-in website tools to seach wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools, initialize_agent, AgentType\n",
    "\n",
    "# define the tools and agent llms bot\n",
    "tools = load_tools(['ddg-search', 'wikipedia'])\n",
    "agent_bot = ChatOpenAI(temperature=0.0, model='gpt-3.5-turbo')\n",
    "\n",
    "# use them to initialize the agent\n",
    "web_agent = initialize_agent(tools, agent_bot, \n",
    "                        agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION, # the agent just do actions and no more interaction\n",
    "                        handle_parsing_errors=True,\n",
    "                        verbose=True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mQuestion: What book did Tom M. Mitchell write?\n",
      "Thought: I can use Wikipedia to find information about Tom M. Mitchell and his books.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Wikipedia\",\n",
      "  \"action_input\": \"Tom M. Mitchell\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mPage: Tom M. Mitchell\n",
      "Summary: Tom Michael Mitchell (born August 9, 1951) is an American computer scientist and the Founders University Professor at Carnegie Mellon University (CMU). He is a founder and former Chair of the Machine Learning Department at CMU. Mitchell is known for his contributions to the advancement of machine learning, artificial intelligence, and cognitive neuroscience and is the author of the textbook Machine Learning. He is a member of the United States National Academy of Engineering since 2010. He is also a Fellow of the American Academy of Arts and Sciences, the American Association for the Advancement of Science and a Fellow and past President of the Association for the Advancement of Artificial Intelligence. In October 2018, Mitchell was appointed as the Interim Dean of the School of Computer Science at Carnegie Mellon.\n",
      "\n",
      "Page: Ensemble learning\n",
      "Summary: In statistics and machine learning, ensemble methods use multiple learning algorithms to obtain better predictive performance than could be obtained from any of the constituent learning algorithms alone.\n",
      "Unlike a statistical ensemble in statistical mechanics, which is usually infinite, a machine learning ensemble consists of only a concrete finite set of alternative models, but typically allows for much more flexible structure to exist among those alternatives.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mAccording to the Wikipedia page, Tom M. Mitchell is the author of the textbook \"Machine Learning\". \n",
      "Final Answer: Tom M. Mitchell wrote the book \"Machine Learning\".\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "question = \"Tom M. Mitchell is an American computer scientist \\\n",
    "and the Founders University Professor at Carnegie Mellon University (CMU)\\\n",
    "what book did he write?\"\n",
    "\n",
    "try:\n",
    "    result = web_agent(question)\n",
    "except:\n",
    "    print(\"exception on external access\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step6.2 build an agent to use the custom tool provided by ourselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool\n",
    "from datetime import date\n",
    "\n",
    "@tool\n",
    "def get_today_date(text: str) -> str:\n",
    "    \"\"\"Returns todays date, use this for any questions related to retrieving today date.\\\n",
    "    The input should always be an empty string,\\\n",
    "    and this function will always return todays date \\\n",
    "    any calculation related to date should occur outside this function.\n",
    "    \"\"\"\n",
    "    return str(date.today())\n",
    "\n",
    "time_agent = initialize_agent(\n",
    "    tools=[get_today_date], llm=agent_bot, \n",
    "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION, # the agent just do actions and no more interaction\n",
    "    handle_parsing_errors=True,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mCould not parse LLM output: Sure! Let me check the date for you.\u001b[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001b[32;1m\u001b[1;3mCould not parse LLM output: I need to use the `get_today_date` tool to retrieve today's date.\u001b[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to use the `get_today_date` tool to retrieve today's date.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"get_today_date\",\n",
      "  \"action_input\": \"\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m2023-12-29\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe current date is 2023-12-29.\n",
      "Final Answer: The current date is 2023-12-29.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "try: result = time_agent(\"could you tell me what the date it is?\")\n",
    "except: print(\"exception on external access\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
